{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Generation with Conditional VAE\n",
    "Train a Conditional Variational Autoencoder to generate handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 50\n",
    "latent_dim = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Dataset size: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVAE Model Definition\n",
    "class ConditionalVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20, num_classes=10):\n",
    "        super(ConditionalVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv_output_size = 128 * 3 * 3\n",
    "        \n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(self.conv_output_size + num_classes, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(256, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim + num_classes, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.conv_output_size),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x, c):\n",
    "        x = self.encoder_conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.cat([x, c], dim=1)\n",
    "        x = self.encoder_fc(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z, c):\n",
    "        z = torch.cat([z, c], dim=1)\n",
    "        x = self.decoder_fc(z)\n",
    "        x = x.view(x.size(0), 128, 3, 3)\n",
    "        x = self.decoder_conv(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, c)\n",
    "        return recon_x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "model = ConditionalVAE(latent_dim=latent_dim, num_classes=num_classes).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    for batch_idx, (data, labels) in enumerate(progress_bar):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        labels_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, logvar = model(data, labels_onehot)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': loss.item() / len(data)})\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'cvae_epoch_{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "torch.save(model.state_dict(), 'cvae_final.pth')\n",
    "print(\"Model saved as 'cvae_final.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize samples\n",
    "def generate_digits(model, digit, num_samples=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        labels = torch.tensor([digit] * num_samples).to(device)\n",
    "        labels_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        generated = model.decode(z, labels_onehot)\n",
    "    return generated.cpu()\n",
    "\n",
    "# Test generation for all digits\n",
    "fig, axes = plt.subplots(10, 5, figsize=(15, 30))\n",
    "\n",
    "for digit in range(10):\n",
    "    generated = generate_digits(model, digit, 5)\n",
    "    for i in range(5):\n",
    "        axes[digit, i].imshow(generated[i].squeeze(), cmap='gray')\n",
    "        axes[digit, i].set_title(f'Digit {digit} - Sample {i+1}')\n",
    "        axes[digit, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('all_generated_digits.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}